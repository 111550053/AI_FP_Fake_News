{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aok-G1ZdFCgG",
        "outputId": "5e3d1af0-67ca-4ed7-b551-3f639e05c753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/MyDrive/AI_FP_Fake_News.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yeJoDs0FZp4",
        "outputId": "c823c40a-ea00-44d5-a907-657c2099b565"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/AI_FP_Fake_News.zip\n",
            "   creating: AI_FP_Fake_News/\n",
            "  inflating: AI_FP_Fake_News/.DS_Store  \n",
            "  inflating: __MACOSX/AI_FP_Fake_News/._.DS_Store  \n",
            "  inflating: AI_FP_Fake_News/preprocess.py  \n",
            "   creating: AI_FP_Fake_News/__pycache__/\n",
            " extracting: AI_FP_Fake_News/README.txt  \n",
            "  inflating: AI_FP_Fake_News/bert.py  \n",
            "   creating: AI_FP_Fake_News/.git/\n",
            "  inflating: AI_FP_Fake_News/main.py  \n",
            "   creating: AI_FP_Fake_News/data/\n",
            "  inflating: AI_FP_Fake_News/__pycache__/preprocess.cpython-310.pyc  \n",
            "  inflating: AI_FP_Fake_News/__pycache__/preprocess.cpython-311.pyc  \n",
            "  inflating: AI_FP_Fake_News/__pycache__/bert.cpython-311.pyc  \n",
            "  inflating: AI_FP_Fake_News/__pycache__/bert.cpython-310.pyc  \n",
            "  inflating: AI_FP_Fake_News/.git/config  \n",
            "   creating: AI_FP_Fake_News/.git/objects/\n",
            "  inflating: AI_FP_Fake_News/.git/HEAD  \n",
            "   creating: AI_FP_Fake_News/.git/info/\n",
            "   creating: AI_FP_Fake_News/.git/logs/\n",
            "  inflating: AI_FP_Fake_News/.git/description  \n",
            "   creating: AI_FP_Fake_News/.git/hooks/\n",
            "   creating: AI_FP_Fake_News/.git/refs/\n",
            "  inflating: AI_FP_Fake_News/.git/index  \n",
            "  inflating: AI_FP_Fake_News/.git/packed-refs  \n",
            "  inflating: AI_FP_Fake_News/data/.DS_Store  \n",
            "  inflating: __MACOSX/AI_FP_Fake_News/data/._.DS_Store  \n",
            "  inflating: AI_FP_Fake_News/data/WELFake_Dataset.csv  \n",
            "  inflating: __MACOSX/AI_FP_Fake_News/data/._WELFake_Dataset.csv  \n",
            "   creating: AI_FP_Fake_News/.git/objects/pack/\n",
            "   creating: AI_FP_Fake_News/.git/objects/info/\n",
            "  inflating: AI_FP_Fake_News/.git/info/exclude  \n",
            "  inflating: AI_FP_Fake_News/.git/logs/HEAD  \n",
            "   creating: AI_FP_Fake_News/.git/logs/refs/\n",
            "  inflating: AI_FP_Fake_News/.git/hooks/commit-msg.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/pre-rebase.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/pre-commit.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/pre-receive.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/post-update.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/pre-merge-commit.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/pre-push.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/update.sample  \n",
            "  inflating: AI_FP_Fake_News/.git/hooks/push-to-checkout.sample  \n",
            "   creating: AI_FP_Fake_News/.git/refs/heads/\n",
            "   creating: AI_FP_Fake_News/.git/refs/tags/\n",
            "   creating: AI_FP_Fake_News/.git/refs/remotes/\n",
            "  inflating: AI_FP_Fake_News/.git/objects/pack/pack-620292d50800f4499a3f5fd0e5442eeb21bcdfc8.pack  \n",
            "  inflating: AI_FP_Fake_News/.git/objects/pack/pack-620292d50800f4499a3f5fd0e5442eeb21bcdfc8.idx  \n",
            "   creating: AI_FP_Fake_News/.git/logs/refs/heads/\n",
            "   creating: AI_FP_Fake_News/.git/logs/refs/remotes/\n",
            "  inflating: AI_FP_Fake_News/.git/refs/heads/main  \n",
            "   creating: AI_FP_Fake_News/.git/refs/remotes/origin/\n",
            "  inflating: AI_FP_Fake_News/.git/logs/refs/heads/main  \n",
            "   creating: AI_FP_Fake_News/.git/logs/refs/remotes/origin/\n",
            "  inflating: AI_FP_Fake_News/.git/refs/remotes/origin/HEAD  \n",
            "  inflating: AI_FP_Fake_News/.git/logs/refs/remotes/origin/HEAD  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/AI_FP_Fake_News/project.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "nNf7AaVAn7-x",
        "outputId": "9d3bcd5a-9f5f-4bcc-cf11-b020e79fb801"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_15325b8e-b1b9-4435-8625-53221f52ed8b\", \"project.pt\", 266086560)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/AI_FP_Fake_News"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRHAcONKFpJD",
        "outputId": "22b7aaab-38cc-4d2e-8334-849dbe90055d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI_FP_Fake_News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUGUG89vF2ik",
        "outputId": "8bfb17c8-ef1a-4e12-9cbb-803f1e9121ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5tTX9g5GDVP",
        "outputId": "e2d0c732-517c-4977-cdd6-bad824bc4120"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "\n",
            "       Unnamed: 0  ... label\n",
            "0           15000  ...     0\n",
            "1           15001  ...     1\n",
            "2           15002  ...     1\n",
            "3           15003  ...     0\n",
            "4           15004  ...     1\n",
            "...           ...  ...   ...\n",
            "57129       72129  ...     0\n",
            "57130       72130  ...     1\n",
            "57131       72131  ...     0\n",
            "57132       72132  ...     0\n",
            "57133       72133  ...     1\n",
            "\n",
            "[57134 rows x 4 columns]\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 265kB/s]\n",
            "config.json: 100% 483/483 [00:00<00:00, 3.33MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 37.8MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 677kB/s]\n",
            "model.safetensors: 100% 268M/268M [00:00<00:00, 329MB/s]\n",
            "100% 7142/7142 [45:06<00:00,  2.64it/s]\n",
            "100% 15000/15000 [03:19<00:00, 75.19it/s]\n",
            "Epoch: 0, F1 score: 0.9789, Precision: 0.9787, Recall: 0.9792, Loss: 0.1269\n"
          ]
        }
      ]
    }
  ]
}